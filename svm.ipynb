{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EM-алгоритм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(43)\n",
    "\n",
    "n = 1000\n",
    "tau = 0.8\n",
    "\n",
    "n1 = int(tau * n)\n",
    "mu1 = np.array([-1.0, -0.5])\n",
    "sigma1 = np.array([\n",
    "    [2.0, 0.0],\n",
    "    [0.0, 2.0],\n",
    "]\n",
    ")\n",
    "\n",
    "n2 = int((1-tau) * n)\n",
    "mu2 = np.array([2.0, 4.0])\n",
    "sigma2 = np.array([\n",
    "    [4.0, -3.0],\n",
    "    [-3.0, 6.0],\n",
    "]\n",
    ")\n",
    "\n",
    "x1 = np.random.multivariate_normal(mu1, sigma1, n1)\n",
    "x2 = np.random.multivariate_normal(mu2, sigma2, n2)\n",
    "x = np.vstack([x1, x2])\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(*x1.T,s=2.5)\n",
    "plt.scatter(*x2.T,s=2.5)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(*x.T,s=2.5,color='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2.1**\n",
    "\n",
    "Перед вам вектор `x` который содержит в себе некоторое количество двумерных векторов, про которые известно, что они распределены как смесь двух нормальных распределений. Используя формулы EM-алгоритма из лекций, реализуйте алгоритм, и найдите параметры распределений: вектора $\\mu_1$ и $\\mu_2$, матрицы $\\Sigma_1$, $\\Sigma_2$, а так же относительное число элементов в первом распределении $\\tau$.\n",
    "\n",
    "Абсолютная точность найденных параметров должна быть лучше $10^{-4}$. Выведите на экран найденные параметры и нарисуйте график разброса точек для вектора `x` на котором цветами покажите оценку вероятности принадлежности данной точки к первому распределению.\n",
    "\n",
    "*Бонусные баллы* можно получить за успешную попытку решить данную задачу на максимум правдоподобия \"в лоб\". Т.е. методом прямой максимизации логарифма функции правдоподобия\n",
    "$$\n",
    "\\arg \\max_{\\mu_1, \\mu_2, \\Sigma_1, \\Sigma_2, \\tau} \\sum_{i=1}^{N} \\log \\left(\\tau N(\\mathbf{x_i} | \\mu_1, \\Sigma_1) + (1-\\tau) N(\\mathbf{x_i} |\\mu_2, \\Sigma_2)\\right)\n",
    "$$\n",
    "с использованием методов численной оптимизации из библиотеки `scipy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2.2**\n",
    "\n",
    "Решите задание **2.1** используя готовый класс `GaussianMixture` (из библиотеки `sklearn`) для аппроксимации данных смесью нормальных распределений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализ главных компонент"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from glob import glob\n",
    "\n",
    "images = [Image.open(file).convert(mode='L') for file in sorted(glob('emoji/*.png'))]\n",
    "print('image count:', len(images))\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15,10))\n",
    "axes = axes.reshape(-1)\n",
    "for i in range(6):\n",
    "    axes[i].imshow(images[i], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = images[0].size\n",
    "data = np.vstack([np.array(image, dtype=float).reshape(-1) for image in images])\n",
    "mean = data.mean(axis=0)\n",
    "data -= mean.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, s, v = np.linalg.svd(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(15,10))\n",
    "axes = axes.reshape(-1)\n",
    "axes[0].set_title('mean')\n",
    "axes[0].imshow(mean.reshape(shape), cmap='inferno')\n",
    "for i in range(5):\n",
    "    axes[i+1].set_title('component {}'.format(i + 1))\n",
    "    axes[i+1].imshow(v[i].reshape(shape), cmap='inferno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = v[:20, :]\n",
    "x = data[30, :]\n",
    "x_hat = np.dot(decoder.T, np.dot(decoder, x))\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15,10))\n",
    "axes[0].imshow((x+mean).reshape(shape), cmap='inferno')\n",
    "axes[1].imshow((x_hat+mean).reshape(shape), cmap='inferno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_std(decoder_size):\n",
    "    decoder = v[:decoder_size, :]\n",
    "    data_hat = np.dot(decoder.T, np.dot(decoder, data.T))\n",
    "    return np.std(data_hat - data.T)\n",
    "\n",
    "std = [evaluate_std(s) for s in range(1,data.shape[0])]\n",
    "plt.figure()\n",
    "plt.plot(std)\n",
    "plt.plot(np.sqrt(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2.3**\n",
    "\n",
    "Перед вами в массиве `image` хранится набор смайликов. Используя готовый класс `PCA` (из библиотеки `sklearn`) для анализа главных компонент, выполните анализ этого набора данных. Постройте изображения первых пяти главных компонент и среднего."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метод опорных векторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(43)\n",
    "\n",
    "x1 = np.random.multivariate_normal(mu1, sigma1, n1)\n",
    "x2 = np.random.multivariate_normal(mu2, sigma2, n2)\n",
    "x = np.concatenate([x1, x2])\n",
    "y = np.concatenate([np.full(x1.shape[0], 0), np.full(x2.shape[0], 1)])\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(*x1.T,s=2.5)\n",
    "plt.scatter(*x2.T,s=2.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2.4**\n",
    "\n",
    "Перед вами данные из задания **2.1**, однако теперь в векторе `y` записан номер распределения к которому принадлежит двухмерная точка. Используя метод опорных векторов `SVC` из пакета `sklearn` с линейным ядром, постройте бинарный классификатор для этих данных. Нанесите раделяющую гиперплоскость (в нашем случае прямую) на график разброса точек.\n",
    "На графике разброса точек цветом обозначьте вероятность принадлежности к первому классу (распределению) по мнению классификатора. Вам поможет метод `predict_proba()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "names = [\"length\", \"width\", \"size\", \"conc\", \"conc1\", \"asym\", \"m3long\", \"m3trans\", \"alpha\", \"dist\", \"class\"]\n",
    "data = pd.read_csv('magic04.csv', names=names)\n",
    "\n",
    "x = np.asarray(data.iloc[:, :-1])\n",
    "y = np.asarray(data.iloc[:, [-1]])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2.5**\n",
    "\n",
    "Ниже определена функция `evaluate`, она нужна для того, чтобы строить график ROC и печатать на экран различные численные меры эффективности бинарного классификатора для данных из задания **1.4**. К сожалению, некоторые формулы потерялись. Восстановите формулы и примените функцию для оценки бинарных классификаторов на базе логистической регрессии `LogisticRegression` и метода опорных векторов `SVC`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "\n",
    "def evaluate(c, x, y):\n",
    "    y_pred = c.predict(x)\n",
    "    scores = c.decision_function(x)\n",
    "\n",
    "    tn, fp, fn, tp = sklearn.metrics.confusion_matrix(y, y_pred, labels=['h', 'g']).ravel()\n",
    "    accuracy  = \n",
    "    precision = \n",
    "    recall    = \n",
    "    specificity = \n",
    "    baccuracy = \n",
    "    f1 = \n",
    "    \n",
    "    print(\"Accuracy                  = {:.4f}\".format(accuracy))\n",
    "    print(\"Ballanced accuracy        = {:.4f}\".format(baccuracy))\n",
    "    print(\"F1                        = {:.4f}\".format(f1))\n",
    "    print(\"Precision (PPV)           = {:.4f}\".format(precision))\n",
    "    print(\"Recall (sensitivity, TPR) = {:.4f}\".format(recall))\n",
    "    print(\"Specificity (TNR, 1-FPR)  = {:.4f}\".format(specificity))\n",
    "    \n",
    "    min_score, max_score = np.min(scores), np.max(scores)\n",
    "    bins = np.linspace(min_score, max_score, 25)\n",
    "    plt.figure()\n",
    "    plt.hist(scores[y.reshape(-1) == 'h'], bins, alpha=0.5, label='Hadron (negative)')\n",
    "    plt.hist(scores[y.reshape(-1) == 'g'], bins, alpha=0.5, label='Gamma (positive)')\n",
    "    plt.xlabel(\"Decision function (value)\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "    \n",
    "    tpr, fpr, _ = sklearn.metrics.roc_curve(y, scores, pos_label='g')\n",
    "    auc = sklearn.metrics.roc_auc_score(y, scores)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.title(\"Receiver operating characteristic\")\n",
    "    plt.xlabel(\"False positive rate\")\n",
    "    plt.ylabel(\"True positive rate\")\n",
    "    print(\"AUC                       = {:.4f}\".format(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "c = LogisticRegression(random_state=42, solver=\"newton-cg\")\n",
    "c.fit(x_train, y_train.reshape(-1))\n",
    "\n",
    "evaluate(c, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "c = SVC(random_state=42)\n",
    "c.fit(x_train, y_train.reshape(-1))\n",
    "\n",
    "evaluate(c, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_dict(x):\n",
    "    if len(x) == 0:\n",
    "        return dict()\n",
    "    return {k: np.asarray([e[k] for e in x]) for k in x[0].keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "C_grid = np.array([1, 10, 100, 1000])\n",
    "\n",
    "scoring = {\n",
    "    \"auc\":       \"roc_auc\",\n",
    "    \"accuracy\":  \"accuracy\",\n",
    "    \"precision\": make_scorer(precision_score, pos_label='g'),\n",
    "    \"recall\":    make_scorer(recall_score, pos_label='g'),\n",
    "}\n",
    "\n",
    "scores = []\n",
    "\n",
    "for C in C_grid:\n",
    "    c = SVC(random_state=42, C=C)\n",
    "    s = cross_validate(c, x, y.reshape(-1), cv=5, scoring=scoring)\n",
    "    scores.append(s)\n",
    "    \n",
    "scores = flat_dict(scores)\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "print(\"fit time = {}\".format(scores['fit_time'].mean(axis=1)))\n",
    "for s in scoring.keys():\n",
    "    print(\"{} = {}\".format(s, scores[\"test_{}\".format(s)].mean(axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2.6**\n",
    "\n",
    "Используя метод кросс-валидации, протестируйте различные ядра для метода опорных векторов и данных из задания **1.4**:\n",
    "полиномиальное ядро с показателями от 3 до 7 включительно, RBF ядро, сигмоидное ядро.\n",
    "Получите таблицу значений точности и AUC для всех случаев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "d = PCA()\n",
    "z_train = d.fit_transform(x_train) \n",
    "z_test = d.transform(x_test)\n",
    "\n",
    "c = SVC(random_state=42)\n",
    "c.fit(z_train, y_train.reshape(-1))\n",
    "\n",
    "evaluate(c, z_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = PCA()\n",
    "z = d.fit_transform(x)\n",
    "plt.plot(np.arange(1, d.singular_values_.shape[0]+1), d.singular_values_, '*')\n",
    "plt.ylabel(\"Singular value\")\n",
    "plt.xlabel(\"n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2.7**\n",
    "\n",
    "Используя метод кросс-валидации, протестируйте метод опорных векторов для данных из задания **1.4** в следующих ситуациях.\n",
    "Используйте анализ главных компонент для исходных данных, затем используйте для обечения классификатора только $n$ полученных главных компонент. Исследуйте все возможные значения $n$.\n",
    "Получите таблицу значений точности и AUC для всех случаев.\n",
    "Постройте график зависимости AUC от размерности используемых входных предикторов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2.8**\n",
    "\n",
    "Проделайте такое же исследование, что и в задании **2.7**, но в этот раз исключайте по одной главной компоненте от первой до последней."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2.9**\n",
    "\n",
    "*Бонусные баллы* можно заработать если предъявить классификатор на основе метода опорных векторов для данных из задания **1.4**, который имел бы наилучшее значение AUC (среди всей группы). Попробуйте перебрать различные гиперпараметры: значения параметра $C$, разные типы ядер, применить анализ главных компонент, и т.п."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
